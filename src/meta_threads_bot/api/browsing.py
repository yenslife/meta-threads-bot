# é€™æ˜¯ä¸€å€‹å¯ä»¥è‡ªå‹•ç€è¦½ threads çš„ API
# ä½¿ç”¨ selenium æ¨¡æ“¬ç€è¦½å™¨æ“ä½œ
from selenium import webdriver
from typing import Any
from rich import print
import time
from bs4 import BeautifulSoup


URL = "https://www.threads.com/"


def browsing() -> list[dict[str, Any]]:
    """
    ç€è¦½ Threads å¹³å°ä¸¦æ“·å–è²¼æ–‡è³‡è¨Š

    åƒæ•¸:
        url: ç‰¹å®šçš„ Threads é é¢ URLï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨é è¨­é¦–é 

    å›å‚³:
        ä¸€å€‹åŒ…å«è²¼æ–‡è³‡è¨Šçš„å­—å…¸æ¸…å–®ï¼Œæ¯å€‹å­—å…¸åŒ…å«è²¼æ–‡ IDã€ä½œè€…ã€å…§å®¹ã€æ™‚é–“ç­‰è³‡è¨Š
    """
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--window-size=1920,1080")  # è¨­å®šè¦–çª—å¤§å°ï¼Œé¿å…å…ƒç´ ä¸å¯è¦‹

    # é¿å…è¢«åµæ¸¬ç‚ºè‡ªå‹•åŒ–å·¥å…·
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)

    driver = webdriver.Chrome(options=options)
    # ä¿®æ”¹ navigator.webdriver æ¨™è¨˜
    driver.execute_script(
        "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
    )

    posts_data: list[dict[str, Any]] = []

    try:
        # å‰å¾€ threads é é¢
        driver.get(URL)
        print(f"ğŸŒ æ­£åœ¨è¼‰å…¥ threads é é¢: {URL}...")
        time.sleep(5)  # ç­‰å¾…é é¢å®Œå…¨è¼‰å…¥

        # æª¢æŸ¥æ˜¯å¦æˆåŠŸè¼‰å…¥
        if "threads.net" in driver.current_url or "threads.com" in driver.current_url:
            print("âœ… æˆåŠŸè¼‰å…¥ threads é é¢")
        else:
            print("âŒ è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ URL")
            return [{"message": "Failed to load threads page"}]

        # å¾€ä¸‹æ»‘å‹•
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)

        # å–å¾—ç›®å‰çš„é é¢ htmlï¼Œç„¶å¾Œä½¿ç”¨ soup åˆ†æ
        page_source = driver.page_source

        soup = BeautifulSoup(page_source, "html.parser")

        # æ‰¾åˆ°æ‰€æœ‰è²¼æ–‡çš„å®¹å™¨
        post_containers = soup.find_all(
            "div", class_="x78zum5 xdt5ytf x1iyjqo2 x1n2onr6"
        )[1]

        print(f"æ‰¾åˆ° {len(post_containers)} ç¯‡è²¼æ–‡")

        for post_container in post_containers:
            post_data = {
                "post_id": None,
                "user_id": None,
                "post_url": None,
                "text_content": None,
                "time_text": None,
                "time_text_from_now": None,
                "datetime": None,
                "like_count": None,
                "comment_count": None,
                "share_count": None,
                "images": None,  # é€™é‚Šæœƒæœ‰å¤šå€‹ï¼Œå› ç‚ºå¦‚æœåªæœ‰ä¸€å¼µåœ–ç‰‡æœƒå‡ºç¾ media url å…¶ä»–å°±æ˜¯æœƒæœ‰å¤šå€‹ image
                "avatar_url": None,
                "videos": None,
                "comments": None,  # å°šæœªå¯¦ä½œ
            }
            # åˆ†æå…§å®¹ï¼ŒåŠ å…¥åˆ° posts_data
            hrefs = post_container.find_all("a", href=True)
            for href in hrefs:
                if "/post/" in href["href"]:
                    post_id = href["href"].split("/post/")[1]
                    post_id = post_id.split("/")[0]  # é¿å…å¤šäº† /media
                    user_id = href["href"].split("/@")[1].split("/")[0]
                    post_data["post_id"] = post_id
                    post_data["user_id"] = user_id
                    post_data["post_url"] = (
                        "https://threads.net/@" + user_id + "/post/" + post_id
                    )
                if "/@" in href["href"]:
                    user_id = href["href"].split("/@")[1].split("/")[0]
                    post_data["user_id"] = user_id

            if not post_data["post_id"]:
                continue

            # img and avatar
            images = post_container.find_all("img")
            if images:
                post_data["images"] = [
                    {image["src"]: image["alt"]} for image in images
                ][1:]
                post_data["avatar_url"] = images[0]["src"]

            # video
            videos = post_container.find_all("video")
            if videos:
                post_data["videos"] = [video["src"] for video in videos]

            # text content
            text_content = post_container.find(
                "span",
                class_="x1lliihq x1plvlek xryxfnj x1n2onr6 x1ji0vk5 x18bv5gf xi7mnp6 x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x1i0vuye xjohtrz xo1l8bm xp07o12 x1yc453h xat24cr xdj266r",
            )
            if text_content:
                post_data["text_content"] = text_content.text

            # time
            time_container = post_container.find("time")
            if time_container:
                post_data["time_text"] = time_container.get("title")
                post_data["datetime"] = time_container.get("datetime")
                post_data["time_text_from_now"] = time_container.text

            # çµ±è¨ˆæ¬¡æ•¸å®¹å™¨
            stats_container = post_container.find(
                "div", class_="x4vbgl9 xp7jhwk x1k70j0n"
            ).find("div", class_="x78zum5")
            for i, stat in enumerate(stats_container):
                state_number = stat.find("span", class_="x17qophe x10l6tqk x13vifvy")
                print(state_number)
                if state_number and state_number.text:
                    state_number = state_number.text
                else:
                    state_number = "0"
                if i == 0:
                    post_data["like_count"] = state_number
                if i == 1:
                    post_data["comment_count"] = state_number
                if i == 2:
                    post_data["repost_count"] = state_number
                if i == 3:
                    post_data["share_count"] = state_number

            posts_data.append(post_data)

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return [{"message": f"Error: {str(e)}"}]
    finally:
        # é—œé–‰ç€è¦½å™¨
        driver.quit()
        print("ğŸ”’ ç€è¦½å™¨å·²é—œé–‰")

    return posts_data


if __name__ == "__main__":
    posts = browsing()
    print(posts)
